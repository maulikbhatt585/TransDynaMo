{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42efd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "\n",
    "from model import TrajectoryModel\n",
    "from trajectory_gpt2 import GPT2Model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4ee70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4772809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import time\n",
    "\n",
    "# start = time()\n",
    "# for i in range(1_000_000):\n",
    "#     print(i)\n",
    "# print(f'run time for printing: {time() - start}')\n",
    "\n",
    "# start = time()\n",
    "# for _ in range(1_000_000):\n",
    "#     pass\n",
    "# print(f'run time for no printing: {time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb7334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cba44e2",
   "metadata": {},
   "source": [
    "## Loading the trajectories from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a44c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_states size torch.Size([500000, 100, 6])\n",
      "traj_actions size torch.Size([500000, 100])\n",
      "state_dim 6\n",
      "n_traj =  500000\n",
      "traj_len =  100\n"
     ]
    }
   ],
   "source": [
    "#Loading trajectories from data\n",
    "# traj_states = torch.load(\"data/acrobot_states.pt\")\n",
    "# traj_actions = torch.load(\"data/acrobot_actions.pt\")\n",
    "\n",
    "traj_states = torch.load(\"data/pendulum_states.pt\")\n",
    "traj_actions = torch.load(\"data/pendulum_actions.pt\")\n",
    "\n",
    "traj_states.to(device)\n",
    "traj_states.to(device)\n",
    "print(\"traj_states size\", traj_states.size())\n",
    "print(\"traj_actions size\", traj_actions.size())\n",
    "state_dim  = traj_states.size()[2]\n",
    "print(\"state_dim\", state_dim)\n",
    "#print(\"act_dim\", act_dim)\n",
    "act_dim  = 1\n",
    "n_traj = traj_states.size()[0]\n",
    "traj_len = traj_states.size()[1]\n",
    "print(\"n_traj = \", n_traj)\n",
    "print(\"traj_len = \", traj_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c507b6",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6581bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.mean(traj_states, dim = 0).repeat(n_traj, 1, 1).size())\n",
    "# print(torch.mean(traj_actions, dim = 0).repeat(n_traj, 1, 1).size())\n",
    "#traj_states = (traj_states - torch.mean(traj_states, dim = 1).repeat(n_traj, 1, 1)) / torch.std(traj_states, dim = 1).repeat(n_traj,1,1)\n",
    "traj_states = (traj_states - torch.mean(traj_states, dim=(0,1), keepdim=True)) / torch.std(traj_states, dim=(0,1), keepdim=True)\n",
    "#traj_actions = (traj_actions - torch.mean(traj_act, dim=0).repeat(n_traj, 1)) / torch.std(traj_actions, dim=0)#.repeat(n_traj, 1)\n",
    "# #yyyy = traj_actions - torch.mean(traj_actions, dim = 0).repeat(n_traj, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4e5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(traj_states.shape)\n",
    "# mean = torch.mean(traj_states, dim=0, keepdim=True)  # shape: [n_traj, 1, dim]\n",
    "# std = torch.std(traj_states, dim=0, keepdim=True)    # shape: [n_traj, 1, dim]\n",
    "# traj_states = (traj_states - mean) / std\n",
    "\n",
    "# print(traj_actions.shape)\n",
    "# mean = torch.mean(traj_actions, dim=0, keepdim=True)  # shape: [n_traj, 1]\n",
    "# std = torch.std(traj_actions, dim=0, keepdim=True)    # shape: [n_traj, 1]\n",
    "# traj_actions = (traj_actions - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca88977",
   "metadata": {},
   "source": [
    "## Splitting the data into Training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a571b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_traj_states = traj_states[0:int(0.95*n_traj),:,:]\n",
    "train_traj_actions = traj_actions[0:int(0.95*n_traj),:]\n",
    "\n",
    "n_train_traj = train_traj_states.size()[0]\n",
    "\n",
    "test_traj_states = traj_states[int(0.95*n_traj):,:,:]\n",
    "test_traj_actions = traj_actions[int(0.95*n_traj):,:]\n",
    "\n",
    "n_test_traj = test_traj_states.size()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182769f",
   "metadata": {},
   "source": [
    "## Function to obtain batch of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9361a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, n_traj, traj_states, traj_actions):\n",
    "    idxs = random.choices(range(n_traj), k=batch_size)\n",
    "    batch_states = traj_states[idxs,:,:]\n",
    "    batch_actions = traj_actions[idxs,:]\n",
    "    \n",
    "    return batch_states, batch_actions.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc21c0",
   "metadata": {},
   "source": [
    "## Decision Transformer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3f1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransDynaMo(TrajectoryModel):\n",
    "\n",
    "    \"\"\"\n",
    "    This model uses GPT to model (state_1, action_1, state_2, action_2, ...)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            state_dim,\n",
    "            act_dim,\n",
    "            hidden_size,\n",
    "            max_length=None,\n",
    "            max_ep_len=100,\n",
    "            action_tanh=True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(state_dim, act_dim, max_length=max_length)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        config = transformers.GPT2Config(\n",
    "            vocab_size=1,  # doesn't matter -- we don't use the vocab\n",
    "            n_embd=hidden_size,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # note: the only difference between this GPT2Model and the default Huggingface version\n",
    "        # is that the positional embeddings are removed (since we'll add those ourselves)\n",
    "        self.transformer = GPT2Model(config)\n",
    "\n",
    "        self.embed_timestep = nn.Embedding(max_ep_len, hidden_size)\n",
    "        self.embed_state = torch.nn.Linear(self.state_dim, hidden_size)\n",
    "        self.embed_action = torch.nn.Linear(self.act_dim, hidden_size)\n",
    "\n",
    "        self.embed_ln = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.predict_state = torch.nn.Linear(hidden_size, self.state_dim)\n",
    "        self.predict_action = nn.Sequential(\n",
    "            *([nn.Linear(hidden_size, self.act_dim)] + ([nn.Tanh()] if action_tanh else []))\n",
    "        )\n",
    "        self.predict_return = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, states, actions, timesteps, attention_mask=None):\n",
    "        \n",
    "        states = states.to(device)\n",
    "        actions = actions.to(device)\n",
    "\n",
    "        batch_size, seq_length = states.shape[0], states.shape[1]\n",
    "\n",
    "        if attention_mask is None:\n",
    "            # attention mask for GPT: 1 if can be attended to, 0 if not\n",
    "\n",
    "            # Create an attention mask tensor of shape (batch_size, seq_length, seq_length) with ones on the diagonal and below\n",
    "            attention_mask = torch.ones((batch_size, seq_length), device = device, dtype=torch.long)\n",
    "        \n",
    "        ones_matrix = torch.triu(torch.ones(seq_length, seq_length)*float('-inf'), diagonal=1)\n",
    "        encoder_attention_mask = ones_matrix.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        zeros_matrix = torch.zeros(batch_size, seq_length, seq_length)\n",
    "\n",
    "        # embed each modality with a different head\n",
    "        state_embeddings = self.embed_state(states)\n",
    "        action_embeddings = self.embed_action(actions)\n",
    "        time_embeddings = self.embed_timestep(timesteps)\n",
    "\n",
    "        # time embeddings are treated similar to positional embeddings\n",
    "        state_embeddings = state_embeddings + time_embeddings\n",
    "        action_embeddings = action_embeddings + time_embeddings\n",
    "        \n",
    "\n",
    "        # which works nice in an autoregressive sense since states predict actions\n",
    "        stacked_inputs = torch.stack(\n",
    "            (state_embeddings, action_embeddings), dim=1\n",
    "        ).permute(0, 2, 1, 3).reshape(batch_size, 2*seq_length, self.hidden_size)\n",
    "        stacked_inputs = self.embed_ln(stacked_inputs)\n",
    "\n",
    "        # to make the attention mask fit the stacked inputs, have to stack it as well\n",
    "        stacked_attention_mask = torch.stack(\n",
    "            (attention_mask, attention_mask), dim=1\n",
    "        ).permute(0, 2, 1).reshape(batch_size, 2*seq_length)\n",
    "        \n",
    "        combined_mask_top = torch.cat([encoder_attention_mask, zeros_matrix], dim=2)\n",
    "        combined_mask_bottom = torch.cat([zeros_matrix, encoder_attention_mask], dim=2)\n",
    "        stacked_encoder_attention_mask = torch.cat([combined_mask_top, combined_mask_bottom], dim=1).to(device)\n",
    "        \n",
    "\n",
    "        # we feed in the input embeddings (not word indices as in NLP) to the model\n",
    "        transformer_outputs = self.transformer(\n",
    "            inputs_embeds=stacked_inputs,\n",
    "            attention_mask=stacked_attention_mask,\n",
    "            encoder_attention_mask = stacked_encoder_attention_mask\n",
    "        )\n",
    "        x = transformer_outputs['last_hidden_state']\n",
    "\n",
    "        # reshape x so that the second dimension corresponds to the original\n",
    "        # returns (0), states (1), or actions (2); i.e. x[:,1,t] is the token for s_t\n",
    "        x = x.reshape(batch_size, seq_length, 2, self.hidden_size).permute(0, 2, 1, 3)\n",
    "\n",
    "        # get predictions\n",
    "        state_preds = self.predict_state(x[:,1])    # predict next state given state and action\n",
    "        action_preds = self.predict_action(x[:,0])  # predict next action given state\n",
    "\n",
    "        return state_preds, action_preds\n",
    "\n",
    "    def get_state(self, states, actions, timesteps, **kwargs):\n",
    "\n",
    "        states = states.reshape(1, -1, self.state_dim)\n",
    "        actions = actions.reshape(1, -1, self.act_dim)\n",
    "        timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "        if self.max_length is not None:\n",
    "            states = states[:,-self.max_length:]\n",
    "            actions = actions[:,-self.max_length:]\n",
    "            timesteps = timesteps[:,-self.max_length:]\n",
    "\n",
    "            # pad all tokens to sequence length\n",
    "            attention_mask = torch.cat([torch.zeros(self.max_length-states.shape[1]), torch.ones(states.shape[1])])\n",
    "            attention_mask = attention_mask.to(dtype=torch.long, device=states.device).reshape(1, -1)\n",
    "            states = torch.cat(\n",
    "                [torch.zeros((states.shape[0], self.max_length-states.shape[1], self.state_dim), device=states.device), states],\n",
    "                dim=1).to(dtype=torch.float32)\n",
    "            actions = torch.cat(\n",
    "                [torch.zeros((actions.shape[0], self.max_length - actions.shape[1], self.act_dim),\n",
    "                             device=actions.device), actions],\n",
    "                dim=1).to(dtype=torch.float32)\n",
    "            timesteps = torch.cat(\n",
    "                [torch.zeros((timesteps.shape[0], self.max_length-timesteps.shape[1]), device=timesteps.device), timesteps],\n",
    "                dim=1\n",
    "            ).to(dtype=torch.long)\n",
    "        else:\n",
    "            attention_mask = None\n",
    "\n",
    "        state_preds, action_preds = self.forward(\n",
    "            states, actions, timesteps, attention_mask=attention_mask, **kwargs)\n",
    "        \n",
    "#         print(state_preds.size())\n",
    "#         print(state_preds[0,-1].size())\n",
    "\n",
    "        return state_preds[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792ea08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d78346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TransDynaMo(\n",
    "#             state_dim=state_dim,\n",
    "#             act_dim=act_dim,\n",
    "#             max_length=20,\n",
    "#             max_ep_len=100,\n",
    "#             hidden_size=128,\n",
    "#             n_layer=3,\n",
    "#             n_head=4,\n",
    "#             n_inner=4*128,\n",
    "#             activation_function='relu',\n",
    "#             n_positions=1024,\n",
    "#             resid_pdrop=0.1,\n",
    "#             attn_pdrop=0.1,\n",
    "#             n_ctx=600\n",
    "#         )\n",
    "model = TransDynaMo(\n",
    "            state_dim=state_dim,\n",
    "            act_dim=act_dim,\n",
    "            max_length=20,\n",
    "            max_ep_len=100,\n",
    "            hidden_size=1600,  # GPT-2 XL \n",
    "            n_layer=48, \n",
    "            n_head=25,  \n",
    "            n_inner=4*1600,  \n",
    "            activation_function='relu',\n",
    "            n_positions=1024,\n",
    "            resid_pdrop=0.1,\n",
    "            attn_pdrop=0.1,\n",
    "            n_ctx=600  \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98daa8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328470ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "batch_size = 256\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lambda steps: min((steps+1)/10000, 1)\n",
    ")\n",
    "\n",
    "n_epochs = 2000\n",
    "\n",
    "loss_horizon = 6\n",
    "\n",
    "train_losses = torch.zeros(n_epochs)\n",
    "\n",
    "for n in range(n_epochs):\n",
    "    print('epoch: ', n)\n",
    "    state_batch, action_batch = get_batch(batch_size, n_train_traj, train_traj_states, train_traj_actions)\n",
    "\n",
    "    state_pred, action_preds = model.forward(state_batch, action_batch, (torch.arange(0,traj_len,1).unsqueeze(0)).to(device))\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    #l = loss(state_pred,state_batch.to(device))\n",
    "    l = loss(state_pred[:,0:loss_horizon,:],state_batch[:,0:loss_horizon,:].to(device))\n",
    "    train_losses[n] = l.detach().cpu().item()\n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f6619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ef4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Pendulum Training Loss\")\n",
    "plt.savefig(\"figures/pendulum_training_loss_mse.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f5478",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803c38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "n_eval = 100\n",
    "eval_losses = torch.zeros(n_eval)\n",
    "\n",
    "#states_eval_batch, actions_eval_batch = get_batch(n_eval, n_test_traj, test_traj_states, test_traj_actions)\n",
    "\n",
    "for n in range(n_eval):\n",
    "\n",
    "    states_eval_batch, actions_eval_batch = get_batch(1, n_test_traj, test_traj_states, test_traj_actions)\n",
    "    state = states_eval_batch[0,0,:]\n",
    "    action = actions_eval_batch[0,0,:]\n",
    "\n",
    "    # we keep all the histories on the device\n",
    "    # note that the latest action will be \"padding\"\n",
    "    states = state.reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "    actions = action.reshape(1, act_dim).to(device=device, dtype=torch.float32)\n",
    "    sim_states = []\n",
    "\n",
    "    episode_return, episode_length = 0, 0\n",
    "    for t in range(99):\n",
    "\n",
    "        # add padding\n",
    "        actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "\n",
    "        pred_state = model.get_state(\n",
    "            states.to(dtype=torch.float32) ,\n",
    "            actions.to(dtype=torch.float32),\n",
    "            (torch.arange(0,t+1,1).unsqueeze(0)).to(device)\n",
    "        )\n",
    "\n",
    "        actions[-1] = actions_eval_batch[0,t+1,:].reshape(1, act_dim)\n",
    "\n",
    "        cur_state = (pred_state).to(device=device).reshape(1, state_dim)\n",
    "        states = torch.cat([states, cur_state], dim=0)\n",
    "        \n",
    "    loss = nn.MSELoss()\n",
    "    l = loss(states.unsqueeze(0),states_eval_batch.to(device))\n",
    "    eval_losses[n] = l.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70928b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(eval_losses)\n",
    "plt.xlabel(\"Loss Values\")\n",
    "plt.ylabel(\"Number of Trajectories\")\n",
    "plt.title(\"Pendulum Evaluation Loss Histogram\")\n",
    "plt.savefig(\"figures/pendulum_evaluation_loss_hist_mse.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8f1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca362c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "n_min = torch.argmin(eval_losses).item()\n",
    "\n",
    "n_eval = 1\n",
    "eval_losses_2 = torch.zeros(99)\n",
    "\n",
    "#states_i, actions_i = states_eval_batch[n_min,:,:].unsqueeze(0), actions_eval_batch[n_min,:,:].unsqueeze(0)\n",
    "\n",
    "for n in range(n_eval):\n",
    "\n",
    "    states_i, actions_i = get_batch(1, n_test_traj, test_traj_states, test_traj_actions)\n",
    "\n",
    "    state = states_i[0,0,:]\n",
    "    action = actions_i[0,0,:]\n",
    "\n",
    "    # we keep all the histories on the device\n",
    "    # note that the latest action will be \"padding\"\n",
    "    states = state.reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "    actions = action.reshape(1, act_dim).to(device=device, dtype=torch.float32)\n",
    "    sim_states = []\n",
    "\n",
    "    episode_return, episode_length = 0, 0\n",
    "    for t in range(99):\n",
    "\n",
    "        # add padding\n",
    "        actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "\n",
    "        pred_state = model.get_state(\n",
    "            states.to(dtype=torch.float32) ,\n",
    "            actions.to(dtype=torch.float32),\n",
    "            (torch.arange(0,t+1,1).unsqueeze(0)).to(device)\n",
    "        )\n",
    "\n",
    "        actions[-1] = actions_i[0,t+1].reshape(1, act_dim)\n",
    "\n",
    "        cur_state = (pred_state).to(device=device).reshape(1, state_dim)\n",
    "        states = torch.cat([states, cur_state], dim=0)\n",
    "        \n",
    "#         print(states.size())\n",
    "#         print(states_i[0,0:t+2,:].size())\n",
    "        \n",
    "        loss = nn.MSELoss()\n",
    "        l = loss(states,(states_i[0,0:t+2,:]).to(device))\n",
    "        eval_losses_2[t] = l.detach().cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e695b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(eval_losses_2)\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Pendulum Evaluation Loss vs Time\")\n",
    "plt.savefig(\"figures/pendulum_evaluation_loss_time_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c402539",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = states_i - states.to('cpu')\n",
    "diff = diff.detach().numpy()\n",
    "plt.plot(diff[0,:,0], label = \"x\")\n",
    "plt.plot(diff[0,:,1], label = \"y\")\n",
    "plt.plot(diff[0,:,2], label = \"angular velocity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time Steps\")\n",
    "#plt.ylim([-6,6])\n",
    "#plt.ylabel(\"Loss\")\n",
    "plt.title(\"Pendulum - Difference of Predicted vs Real Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_test_diff_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states_i[0,:,0], label = \"x\")\n",
    "plt.plot(states_i[0,:,1], label = \"y\")\n",
    "plt.plot(states_i[0,:,2], label = \"angular velocity\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "\n",
    "#plt.ylabel(\"Loss\")\n",
    "#plt.ylim([-6,6])\n",
    "\n",
    "plt.title(\"Pendulum - Actual Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_test_real_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc344518",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = states.detach().cpu()\n",
    "plt.plot(states[0:,0], label = \"x\")\n",
    "plt.plot(states[:,1], label = \"y\")\n",
    "plt.plot(states[:,2], label = \"angular velocity\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time Steps\")\n",
    "#plt.ylabel(\"Loss\")\n",
    "#plt.ylim([-6,6])\n",
    "plt.title(\"Pendulum - Predicted Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_pred_real_mse_2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(states_i[0,0:loss_horizon,0], label = \"x_actual\")\n",
    "#plt.plot(states[0,0:loss_horizon,0], label = \"x\")\n",
    "\n",
    "plt.plot(states[0:loss_horizon,0], label = \"x\")\n",
    "\n",
    "plt.plot(states_i[0,0:loss_horizon,0], label = \"x_actual\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "\n",
    "#plt.ylabel(\"Loss\")\n",
    "#plt.ylim([-6,6])\n",
    "\n",
    "#plt.title(\"Pendulum - Actual Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_test_real_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e939596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states[0:loss_horizon,1], label = \"y\")\n",
    "\n",
    "plt.plot(states_i[0,0:loss_horizon,1], label = \"y_actual\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "\n",
    "#plt.ylabel(\"Loss\")\n",
    "#plt.ylim([-6,6])\n",
    "\n",
    "#plt.title(\"Pendulum - Actual Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_test_real_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf490ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(states[0:loss_horizon,2], label = \"w\")\n",
    "\n",
    "plt.plot(states_i[0,0:loss_horizon,2], label = \"w_actual\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Time Steps\")\n",
    "\n",
    "#plt.ylabel(\"Loss\")\n",
    "#plt.ylim([-6,6])\n",
    "\n",
    "#plt.title(\"Pendulum - Actual Trajectory\")\n",
    "plt.savefig(\"figures/pendulum_test_real_mse_2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec408a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
